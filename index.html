<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite App</title>
  </head>
  <body>
    <canvas id="bg"></canvas>
    <main>

      <header>
        <h1>Rayhan Papar</h1>
        <p>Welcome to my Personal Portfolio Website!</p>

        <blockquote>
          <p>I love programming, engineering, and robotics!</p>
        </blockquote>
        <blockquote>
          <p>This website features a little bit about me, as well as several overviews of projects I have done.</p>
        </blockquote>
    
      </header>
      <section>
        <h2>About Me</h2>
        <p>Hello! My name is Rayhan Papar, and I am a 9th grade student at the Academy of Science and Technology. This website is mainly a way to show my projects and experience in an intuitive manner.</p>
        <p>Some of my hobbies include programming, robotics, percussion, and tennis.</p>
        <p>Continue on to see some of the projects I have coded for science fairs, competitions, and fun in general! You can click on each box to access an intuitive and in depth explanation of each project with the aid of background 3D visuals.</p>

      </section>
      <section>
        <h2>Development of a Novel Live Surgical Aid for the Removal of Brain Tumors using Augmented Reality and Deep Learning</h2>
        <p>Through the use of Augmented Reality (AR) and Deep Learning, I have developed a surgical aid that surgeons can use during brain tumor removals. This system first uses deep learning models I trained on 350+ MRIs to generate patient specific models of the tumor and brain blood vessels. I then developed a Unity application to render these 3D models in the surgeons field of view using the Microsoft Hololens. This system essentially gives the surgeon X-ray vision, allowing them to see the exact position of the tumor and blood vessels overlayed onto the patient like a hologram.</p>
      </section>
      <section>
        <h2>A Novel Distress Detector using Natural Language Processing and Computer Vision</h2>
        <p>I have developed a software that functions through a security camera, taking in audio and video footage. This system runs several artificial intelligence models I trained on this realtime data to detect five factors: speech, volume, speech emotion, facial emotion, and pose estimation. From this data, I could derive, in realtime, whether a person in the cameras field of view or hearing was having a heart attack, choking, having a headache, expressing negative speech or facial emotion, and saying words such as "help." This system would then alert first responders if the distress score went over a certain threshold. This system could greatly aid people who live alone, as it would automatically alert the necessary personnel to save valuable time.</p>
      </section>
    <div id="app"></div>
    <script type="module" src="/main.js"></script>
  </body>
</html>
